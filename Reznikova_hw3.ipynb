{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini',\n",
    "                 max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth or np.iinfo(np.int32).max\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        return np.square(l_c).sum(axis=1) / l_s +\\\n",
    "            np.square(r_c).sum(axis=1) / r_s -\\\n",
    "            np.square(l_c + r_c).sum(axis=1) / (l_s + r_s)\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return (np.log2(l_c / np.expand_dims(l_s,\n",
    "                                             axis=1)) * l_c).sum(axis=1) +\\\n",
    "            (np.log2(r_c / np.expand_dims(r_s,\n",
    "                                          axis=1)) * r_c).sum(axis=1) -\\\n",
    "            (np.log2((l_c + r_c) / np.expand_dims((l_s + r_s),\n",
    "                                                  axis=1)) *\n",
    "             (l_c + r_c)).sum(axis=1)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return l_c.max() + r_c.max() - (l_c + r_c).max()\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[: max(1, int(np.sqrt(n_feature)))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[: max(1, int(np.log2(n_feature)))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        th_idx = np.where(y[1:] != y[:-1])[0] + 1\n",
    "        if not th_idx.any():\n",
    "            return [0, 0]\n",
    "        seq = th_idx - np.append([0], th_idx[:-1])\n",
    "        change_cl = np.zeros((th_idx.shape[0], self.num_class))\n",
    "        change_cl[np.arange(th_idx.shape[0]), y[th_idx - 1]] = 1\n",
    "        class_counts = change_cl * seq.reshape(-1, 1)\n",
    "        r_c_ = np.cumsum(class_counts, axis=0)\n",
    "        l_c_ = np.bincount(y, minlength=self.num_class) - r_c_\n",
    "        epsilon = 0.001\n",
    "        r_c_[r_c_ == 0] = epsilon\n",
    "        l_c_[l_c_ == 0] = epsilon\n",
    "        l_s_ = l_c_.astype('int').sum(axis=1)\n",
    "        r_s_ = y.shape[0] - l_s_\n",
    "        imp_mat = self.G_function(l_c_, l_s_, r_c_, r_s_)\n",
    "        return [imp_mat.max(), x[r_s_[imp_mat.argmax()] - 1]]\n",
    "\n",
    "    def __stop_criterion(self, cur_depth, samples, max_proba):\n",
    "        depth = self.max_depth > cur_depth\n",
    "        sample = self.min_samples_split < samples\n",
    "        share = self.sufficient_share > max_proba\n",
    "        if depth and sample and share:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        y_proba = np.bincount(y, minlength=self.num_class) / y.shape[0]\n",
    "        if self.__stop_criterion(depth, y.shape[0], y_proba.max()):\n",
    "#           y_pred = self.classes[y_proba.argmax()]\n",
    "            y_pred = y_proba.argmax()\n",
    "            self.tree.update({node_id: (self.__class__.LEAF_TYPE,\n",
    "                                        y_pred, y_proba)})\n",
    "        else:\n",
    "            f_ids = self.get_feature_ids(x.shape[1])\n",
    "            node_g = np.array([])\n",
    "            node_th = np.array([])\n",
    "            for f_i in f_ids:\n",
    "                x_i, y_i = self.__sort_samples(x[:, f_i], y)\n",
    "                g, th = self.__find_threshold(x_i, y_i)\n",
    "                node_g = np.append(node_g, g)\n",
    "                node_th = np.append(node_th, th)\n",
    "            best = node_g.argmax()\n",
    "            best_f_i = f_ids[best]\n",
    "            best_threashold = node_th[best]\n",
    "            self.feature_importances_[best] += node_g.max()\n",
    "            x_l, x_r, y_l, y_r = self.__div_samples(x,\n",
    "                                                    y,\n",
    "                                                    best_f_i,\n",
    "                                                    best_threashold)\n",
    "            if len(y_l) == 0 or len(y_r) == 0:\n",
    "                y_proba = np.bincount(y, minlength=self.num_class) / y.shape[0]\n",
    "#                 y_pred = self.classes[y_proba.argmax()]\n",
    "                y_pred = y_proba.argmax()\n",
    "                self.tree.update({node_id: (self.__class__.LEAF_TYPE,\n",
    "                                            y_pred, y_proba)})\n",
    "                return\n",
    "            self.tree.update({node_id: (self.__class__.NON_LEAF_TYPE,\n",
    "                                        best_f_i,\n",
    "                                        best_threashold)})\n",
    "#             print('tree: ', self.tree[node_id])\n",
    "            self.__fit_node(x_l, y_l, node_id * 2 + 1, depth + 1)\n",
    "            self.__fit_node(x_r, y_r, node_id * 2 + 2, depth + 1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "#         self.classes = np.unique(y)\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.shape[0]\n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 ms, sys: 1.39 ms, total: 3.64 ms\n",
      "Wall time: 2.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 ms, sys: 3.29 ms, total: 26.3 ms\n",
      "Wall time: 23.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363636363636364"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363636363636364"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/speed-dating-experiment/Speed Dating Data.csv',\n",
    "                 encoding='latin1')\n",
    "df = df.iloc[:, :97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "df = df.drop(['id', 'idg', 'condtn', 'position',\n",
    "              'positin1', 'order', 'partner',\n",
    "              'age_o', 'race_o', 'pf_o_att', \n",
    "              'pf_o_sin', 'pf_o_int', 'pf_o_fun',\n",
    "              'pf_o_amb', 'pf_o_sha', 'dec_o',\n",
    "              'attr_o', 'sinc_o', 'intel_o',\n",
    "              'fun_o', 'amb_o', 'shar_o', 'like_o',\n",
    "              'prob_o','met_o', 'field', 'undergra',\n",
    "              'from', 'zipcode', 'income', 'sports',\n",
    "              'tvsports','exercise','dining', 'round',\n",
    "              'museums','art','hiking','gaming',\n",
    "              'clubbing','reading','tv','theater',\n",
    "              'movies','concerts','music','shopping',\n",
    "              'yoga', 'expnum'], axis=1)\n",
    "\n",
    "df = df.dropna(subset=['age'])\n",
    "\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df.field_cd = df.field_cd.astype(np.int)\n",
    "\n",
    "df.race = df.race.astype(np.int)\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "df = df.drop(['career'], axis=1)\n",
    "df.career_c = df.career_c.astype(np.int)\n",
    "\n",
    "# df.loc[:, 'mn_sat'] =\\\n",
    "#     df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "# df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].fillna(0)\n",
    "df = df.drop(['mn_sat'], axis=1)\n",
    "\n",
    "# df.loc[:, 'tuition'] =\\\n",
    "#     df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "# df.loc[:, 'tuition'] = df.loc[:, 'tuition'].fillna(0)\n",
    "df = df.drop(['tuition'], axis=1)\n",
    "\n",
    "df = df.dropna(subset=['imprelig', 'imprace', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] =\\\n",
    "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "               'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "           'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                'fun1_1', 'amb1_1', 'shar1_1']].T/\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] =\\\n",
    "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "               'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "           'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                'fun2_1', 'amb2_1', 'shar2_1']].T/\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['temp_totalsum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)\n",
    "\n",
    "df = df.drop(['wave'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1).dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr',\n",
    "                                          'samerace'], axis=1).dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'\n",
    "\n",
    "df_male.pid = df_male.pid.astype(np.int)\n",
    "df_female.pid_f = df_female.pid_f.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_male.join(df_female.set_index('iid_f'), how='right', on='pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     int_corr  samerace   age  field_cd  race  imprace  imprelig  goal  date  \\\n",
      "100      0.14         0  27.0         8     2      7.0       3.0   1.0   5.0   \n",
      "110      0.54         0  22.0         1     2      1.0       1.0   1.0   1.0   \n",
      "120      0.16         1  22.0         1     4      3.0       5.0   2.0   7.0   \n",
      "130      0.61         0  23.0         1     2      1.0       1.0   2.0   4.0   \n",
      "140      0.21         0  24.0         1     3      3.0       1.0   1.0   4.0   \n",
      "\n",
      "     go_out    ...     sinc2_1_f  intel2_1_f  fun2_1_f  amb2_1_f  shar2_1_f  \\\n",
      "100     4.0    ...          20.0        15.0      20.0       5.0        5.0   \n",
      "110     1.0    ...          20.0        15.0      20.0       5.0        5.0   \n",
      "120     1.0    ...          20.0        15.0      20.0       5.0        5.0   \n",
      "130     1.0    ...          20.0        15.0      20.0       5.0        5.0   \n",
      "140     1.0    ...          20.0        15.0      20.0       5.0        5.0   \n",
      "\n",
      "     attr3_1_f  sinc3_1_f  fun3_1_f  intel3_1_f  amb3_1_f  \n",
      "100        6.0        8.0       8.0         8.0       7.0  \n",
      "110        6.0        8.0       8.0         8.0       7.0  \n",
      "120        6.0        8.0       8.0         8.0       7.0  \n",
      "130        6.0        8.0       8.0         8.0       7.0  \n",
      "140        6.0        8.0       8.0         8.0       7.0  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "target = df_join.loc[:, 'match'].values\n",
    "df_join = df_join.drop(['match', 'iid', 'pid', 'pid_f'], axis=1)\n",
    "data = df_join.values\n",
    "\n",
    "print(df_join.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDD_my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "SDD_clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SDD, X_test_SDD, y_train_SDD, y_test_SDD = train_test_split(data, target,\n",
    "                                                    test_size=0.01, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 3.75 ms, total: 106 ms\n",
      "Wall time: 104 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time SDD_clf.fit(X_train_SDD, y_train_SDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 8.69 ms, total: 1.19 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%time SDD_my_clf.fit(X_train_SDD, y_train_SDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4029850746268657"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=SDD_clf.predict(X_test_SDD), y_true=y_test_SDD, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=SDD_my_clf.predict(X_test_SDD), y_true=y_test_SDD, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08083297 0.00681826 0.02850256 0.02182158 0.00793687 0.0187251\n",
      " 0.01082891 0.01260096 0.02032261 0.01647445] , ...\n",
      "[0.03708706 0.03685213 0.02867055 0.03263559 0.02183774 0.05207775\n",
      " 0.01090708 0.01734712 0.03868061 0.025555  ] , ...\n"
     ]
    }
   ],
   "source": [
    "# Добавьте функционал, который определяет значения feature importance.\n",
    "\n",
    "print(SDD_clf.feature_importances_[:10], ', ...')\n",
    "print(SDD_my_clf.feature_importances_[:10], ', ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn DecisionTreeClassifier:\n",
      "\n",
      "('int_corr', 0.08083297082910103)\n",
      "('amb3_1_f', 0.0408342304573731)\n",
      "('exphappy_f', 0.030387920332305574)\n",
      "('fun2_1_f', 0.02907707013181051)\n",
      "('fun1_1_f', 0.028970194144291805)\n",
      "('career_c_f', 0.028572191548502636)\n",
      "('age', 0.028502555759906564)\n",
      "('age_f', 0.027017507458596053)\n",
      "('sinc1_1', 0.02467887822865914)\n",
      "('intel1_1_f', 0.023549510546904996)\n",
      "\n",
      "MyDecisionTreeClassifier:\n",
      "\n",
      "('age_f', 0.027017507458596053)\n",
      "('imprace', 0.018725099198650015)\n",
      "('fun3_1', 0.002861581110448058)\n",
      "('intel1_1', 0.020568612630350827)\n",
      "('date', 0.02032261222201473)\n",
      "('career_c', 0.009476480998626547)\n",
      "('int_corr', 0.08083297082910103)\n",
      "('exphappy', 0.015643570085250635)\n",
      "('samerace', 0.0068182559593587076)\n",
      "('shar1_1', 0.008158511763778435)\n"
     ]
    }
   ],
   "source": [
    "# Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже)\n",
    "# для MyDecisionTreeClassifier и DecisionTreeClassifier так,\n",
    "# чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier.\n",
    "# Используем данные Speed Dating Data.\n",
    "\n",
    "f_idx = np.argsort(SDD_clf.feature_importances_)[::-1]\n",
    "my_f_idx = np.argsort(SDD_my_clf.feature_importances_)[::-1]\n",
    "\n",
    "features = zip(df_join.columns[f_idx][:10],\n",
    "           SDD_clf.feature_importances_[f_idx][:10])\n",
    "my_features = zip(df_join.columns[my_f_idx][:10],\n",
    "                  SDD_clf.feature_importances_[my_f_idx][:10])\n",
    "# features\n",
    "\n",
    "\n",
    "print('Sklearn DecisionTreeClassifier:\\n', *features, sep='\\n')\n",
    "print('\\nMyDecisionTreeClassifier:\\n', *my_features, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'max_depth': 7, 'min_samples_split': 8}\n",
      "0.6894952574263359\n"
     ]
    }
   ],
   "source": [
    "# С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса\n",
    "# (Выберете 2-3 параметра).\n",
    "# Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint as randint\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(2, 8),\n",
    "    'min_samples_split': randint(5, 10),\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# model = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=123,\n",
    "                                  n_estimators=50,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(model_RF, param_distributions=param_grid,\n",
    "                                   n_iter=200, n_jobs=-1, cv=cv,\n",
    "                                   scoring='roc_auc', random_state=123)\n",
    "# А дальше, просто .fit()\n",
    "random_search.fit(data, target)\n",
    "\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(random_search.best_score_)\n",
    "\n",
    "# best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
